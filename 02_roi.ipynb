{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bdc794b-8d17-4fc6-bd1d-44813ab27969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.core import *\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from selectivesearch import selective_search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44ef33b-9cf2-4a20-9d29-4590ddae111b",
   "metadata": {},
   "source": [
    "**Task:**\n",
    "Given region proposals for an image, annotate each Region of Interest (ROI) with\n",
    "* Class that it belongs to\n",
    "* Offset from the ground truth bounding box\n",
    "* IOU of the ROI with the ground truth bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5b4e4bf-49a3-454e-8da8-a61db4c61b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data['annotations'])\n",
    "df.category_id = df.category_id.replace(cat_id2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b821d4f-dbb0-43bb-b1ce-c69697e09592",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "ds = ObjectDataset(df, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1ae03de-b482-499a-b0b5-054db72a8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ROIs:\n",
    "    boxes: torch.FloatTensor\n",
    "    categories: Optional[torch.IntTensor] = None\n",
    "    offsets: Optional[torch.FloatTensor] = None\n",
    "    ious: Optional[torch.FloatTensor] = None\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.categories = torch.full((self.boxes.shape[0],), 0, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b86560ca-3d01-4552-80f1-89d711c0981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rois(img):\n",
    "    _, regions = selective_search(img.permute(1,2,0), scale=200, min_size=100)\n",
    "    rois = torch.tensor([r['rect'] for r in regions])\n",
    "    sizes = torch.tensor([r['size'] for r in regions])\n",
    "    img_area = img.shape[1]*img.shape[2]\n",
    "    mask = (sizes>0.05*img_area) & (sizes<img_area)\n",
    "    return ROIs(rois[mask, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456a5d9d-4fb6-47d4-9b58-d7f70f1ce668",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awesomeville/miniforge3/lib/python3.12/site-packages/skimage/feature/texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60, 4]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "img, boxes, ids = ds[8]\n",
    "rois = extract_rois(img)\n",
    "print(rois.boxes.shape, boxes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "104abd47-4c86-4760-8567-15d4f9c8fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ious(rois, bboxes, epsilon=1e-5):\n",
    "    rois = torch.cat([rois[:,:2], rois[:,:2]+rois[:,2:]], dim=1)\n",
    "    bboxes = torch.cat([bboxes[:,:2], bboxes[:,:2]+bboxes[:,2:]], dim=1)\n",
    "\n",
    "    inter_xmin = torch.max(rois[:, None, 0], bboxes[None, :, 0])\n",
    "    inter_ymin = torch.max(rois[:, None, 1], bboxes[None, :, 1])\n",
    "    inter_xmax = torch.min(rois[:, None, 2], bboxes[None, :, 2])\n",
    "    inter_ymax = torch.min(rois[:, None, 3], bboxes[None, :, 3])\n",
    "\n",
    "    inter_w = (inter_xmax-inter_xmin).clamp(min=0)  # Ensure non-negative width\n",
    "    inter_h = (inter_ymax-inter_ymin).clamp(min=0)  # Ensure non-negative height\n",
    "    intersection = inter_w*inter_h\n",
    "    \n",
    "    area1 = (rois[:, 2]-rois[:, 0])*(rois[:, 3]-rois[:, 1])\n",
    "    area2 = (bboxes[:, 2]-bboxes[:, 0])*(bboxes[:, 3]-bboxes[:, 1])\n",
    "    union = area1[:, None]+area2[None, :]-intersection\n",
    "    \n",
    "    return intersection/(union+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfbf442a-5704-481e-9adf-b103a239d065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ious(rois.boxes, boxes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64f11771-76d2-469b-ab88-ebec41eb2b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_rois(bboxes, ids, rois, cat_thresh=0.3):\n",
    "    ious = get_ious(rois.boxes, bboxes)\n",
    "    max_ious, max_idxs = ious.max(dim=1)\n",
    "    valid_mask = max_ious>cat_thresh\n",
    "    rois.categories[valid_mask] = ids[max_idxs[valid_mask]]\n",
    "    rois.offsets = bboxes[max_idxs]-rois.boxes\n",
    "    rois.ious = max_ious\n",
    "    return rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38aef963-d2ff-4922-a29c-3e4321d52dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = annotate_rois(boxes, ids, rois)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58da010e-9866-4d9c-a0cb-d69241bf1dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
